# Noisy-Learning
Link to the paper : https://ieeexplore.ieee.org/document/9806738
Motivated by the growing interest in machine learning on nanoscale edge devices, this is a study of the effect of hardware noise and quantization errors on the accuracy of inference by linear classifiers.
Machine learning is predicted to pervade every edge device
that the upcoming high speed 5G networks are expected to
connect. Many of these devices will be running critical
applications like health monitoring, elderly and child care and
industrial sensing. So, accurate execution of machine learning
algorithms on these edge devices is of paramount importance. This leads to the crucial question: can reliable
learning and inference be done on the noisy and error prone
hardware of edge devices?
This question is quite broad and can be resolved decisively
only in due course. Here, we ask a much more modest
question: how significant is the impact of hardware noise on
linear classifiers and is there a strategy to mitigate it that is
amenable to implementation on a low complexity edge device? Using simple and well accepted stochastic models for
hardware errors we demonstrate that the inference of linear
classifiers on real as well synthetic data are significantly
affected by noise. So, we propose an easy to implement
strategy to make the inference of the classifier robust against
hardware errors. This was possible because of the immense help from my colleague Ms. Prakruthi Pradeep and my advisor Mr. Avhishek Chatterjee
